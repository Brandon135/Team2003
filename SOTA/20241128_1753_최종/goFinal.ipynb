{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "from tiki.mini import TikiMini\n",
    "from testing import TestCapture, read_realtime, capture_generator\n",
    "os.environ['YOLO_VERBOSE'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiki = TikiMini()\n",
    "tiki.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "# 실전용\n",
    "#lower_event = np.array([67, 23, 101])\n",
    "#upper_event = np.array([80, 255, 168])\n",
    "\n",
    "# 연습용\n",
    "lower_event = np.array([41, 57, 50])\n",
    "upper_event = np.array([52, 153, 161])\n",
    "\n",
    "#Byung Ddu ggung\n",
    "#lower_event = np.array([90, 100, 100])\n",
    "#upper_event = np.array([150, 255, 255])\n",
    "\n",
    "#절연테이프\n",
    "#lower_line = np.array([0, 0, 47])\n",
    "#upper_line = np.array([179,147,110])\n",
    "\n",
    "#연습용, 실전용!!!\n",
    "lower_line = np.array([0, 0, 0])\n",
    "upper_line = np.array([220, 70, 130])\n",
    "\n",
    "#실전용마킹!!!\n",
    "#lower_event = np.array([47, 23, 141])\n",
    "#upper_event = np.array([80, 255, 168])\n",
    "\n",
    "\n",
    "roix_s = 280\n",
    "roix_e = 350\n",
    "roiy_s = 170\n",
    "roiy_e = 490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop():\n",
    "    tiki.stop()\n",
    "\n",
    "def turn_90(direction):\n",
    "    turn_power1 = 15\n",
    "    turn_power2 = 15\n",
    "\n",
    "    if direction == 'left':\n",
    "        tiki.counter_clockwise(turn_power1)\n",
    "    elif direction == 'right':\n",
    "        tiki.clockwise(turn_power2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines(image):\n",
    "    \n",
    "    crop_img = image[roix_s:roix_e, roiy_s:roiy_e].copy()\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "    color_mask = cv2.inRange(hsv_image, lower_line, upper_line)\n",
    "    masked_image = cv2.bitwise_and(crop_img, crop_img, mask=color_mask)\n",
    "    gray_mask = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(gray_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    lines, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return crop_img, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 48\n",
    "def adjust_wheel_speed(cx, start_cx):\n",
    "    if (cx > start_cx + 85):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 50)#1시 테스트때 50이엇음\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 10)\n",
    "    elif (cx < start_cx - 85):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 10)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 50)\n",
    "    \n",
    "    # MICRO CONTROL\n",
    "    elif (cx > start_cx + 30):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, a)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 30)\n",
    "    elif (cx < start_cx - 30):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, a)\n",
    "        \n",
    "    # NORMAL\n",
    "    elif (start_cx - 30 < cx < start_cx + 30): \n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 30) \n",
    "\n",
    "    # CURVE\n",
    "    '''\n",
    "    if (cx > start_cx + 70):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 40)#1시 테스트때 50이엇음\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 10)\n",
    "    elif (cx < start_cx - 70):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 10)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 40)\n",
    "    \n",
    "    # MICRO CONTROL\n",
    "    elif (cx > start_cx + 30):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, a)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 30)\n",
    "    elif (cx < start_cx - 30):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, a)\n",
    "        \n",
    "    # NORMAL\n",
    "    elif (start_cx - 30 < cx < start_cx + 30): \n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 30) \n",
    "        '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_event_color(image, lower_event, upper_event):\n",
    "    \n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_event, upper_event)\n",
    "    return mask\n",
    "\n",
    "def calculate_center_area(image, center_width=200, center_height=50):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    center_x = width // 2 \n",
    "    center_y = height // 2 + 10\n",
    "    start_x = center_x - center_width // 2\n",
    "    start_y = center_y - center_height // 2\n",
    "    end_x = start_x + center_width\n",
    "    end_y = start_y + center_height\n",
    "\n",
    "    return (start_x, start_y, end_x, end_y)\n",
    "\n",
    "def detect_event_in_center(center_mask, start_x, start_y):\n",
    "    event_detected = np.sum(center_mask) > 0\n",
    "    \n",
    "    event_point = None\n",
    "    if event_detected:\n",
    "        contours, _ = cv2.findContours(center_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"]) + start_x\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"]) + start_y\n",
    "                event_point = (cx, cy)\n",
    "    \n",
    "    return event_detected, event_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_callback(callbacks,callback, end_time, *argu):\n",
    "    callback = partial(callback, *argu)\n",
    "    callbacks.append((callback, time.time() + end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Event_Handler(callbacks, event_num):\n",
    "    Time90 = 1.5\n",
    "    if event_num == 0:\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        add_callback(callbacks, tiki.stop, 2) \n",
    "        return 20\n",
    "    elif event_num == 1: # mission\n",
    "        add_callback(callbacks, tiki.forward, 0.8, 30)\n",
    "        add_callback(callbacks, turn_90, 2.3, 'left')\n",
    "        add_callback(callbacks, tiki.stop, 2.6)  \n",
    "        return 15\n",
    "    elif event_num == 2:\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        add_callback(callbacks, tiki.stop, 2) \n",
    "        return 40\n",
    "    elif event_num == 3: # mission\n",
    "        add_callback(callbacks, tiki.forward, 0.8, 30)\n",
    "        add_callback(callbacks, turn_90, 2.3, 'left')\n",
    "        add_callback(callbacks, tiki.stop, 3.6)  \n",
    "        return 40\n",
    "    elif event_num == 4:\n",
    "        add_callback(callbacks, turn_90, Time90, 'right')\n",
    "        add_callback(callbacks, tiki.stop, 2) \n",
    "        return 20\n",
    "    elif event_num == 5: # mission\n",
    "        add_callback(callbacks, tiki.forward, 0.8, 30)\n",
    "        add_callback(callbacks, turn_90, 2.3, 'left')\n",
    "        add_callback(callbacks, tiki.stop, 2.6)  \n",
    "        return 80\n",
    "    elif event_num == 6: # mission\n",
    "        add_callback(callbacks, tiki.forward, 0.8, 30)\n",
    "        add_callback(callbacks, turn_90, 2.3, 'left')\n",
    "        add_callback(callbacks, tiki.stop, 2.6)  \n",
    "        return 20\n",
    "    elif event_num == 7:\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        add_callback(callbacks, tiki.forward,3, 30)\n",
    "        return 10\n",
    "    elif event_num == 8:\n",
    "        add_callback(callbacks, tiki.forward,2, 30)\n",
    "        add_callback(callbacks, tiki.stop, 3) \n",
    "        stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/jetson/Workspace/1000.jpg: 480x640 1 friendly person, 1 enemy person, 1 enemy tank, 132.1ms\n",
      "Speed: 6.7ms preprocess, 132.1ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /home/jetson/Workspace/1000.jpg: 480x640 1 friendly person, 1 enemy person, 1 enemy tank, 128.3ms\n",
      "Speed: 4.2ms preprocess, 128.3ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /home/jetson/Workspace/1000.jpg: 480x640 1 friendly person, 1 enemy person, 1 enemy tank, 123.2ms\n",
      "Speed: 5.3ms preprocess, 123.2ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /home/jetson/Workspace/1000.jpg: 480x640 1 friendly person, 1 enemy person, 1 enemy tank, 124.7ms\n",
      "Speed: 4.3ms preprocess, 124.7ms inference, 13.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /home/jetson/Workspace/1000.jpg: 480x640 1 friendly person, 1 enemy person, 1 enemy tank, 122.3ms\n",
      "Speed: 4.3ms preprocess, 122.3ms inference, 10.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, ckpt):\n",
    "        self.model = YOLO(ckpt, verbose=False)\n",
    "        for _ in range(5):\n",
    "            results = self.model.predict('1000.jpg')[0]\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        cap, \n",
    "        vid_widget,\n",
    "        n=15,\n",
    "    ):\n",
    "        \n",
    "        votes = defaultdict(int)\n",
    "        def count_cls(preds):\n",
    "            return tuple(preds.count(i) for i in range(4))\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        for _ in range(n):\n",
    "            frame = read_realtime(cap)\n",
    "        \n",
    "            results = self.model.predict(frame)[0]\n",
    "            annot_frame = results.plot()\n",
    "        \n",
    "            clss = tuple(map(int, results.boxes.cls.cpu().tolist()))\n",
    "            cls_cnt = count_cls(clss)\n",
    "            votes[cls_cnt] += 1\n",
    "            \n",
    "            vid_widget.value = cv2.imencode('.bmp', annot_frame)[1].tobytes()\n",
    "    \n",
    "    \n",
    "        print(*votes.items(), sep='\\n')\n",
    "    \n",
    "        ret = max(votes.keys(), key=lambda x: votes[x])\n",
    "        if ret[2] == 0 and ret[3]:\n",
    "            #tiki.log('FIRE')\n",
    "            for _ in range(3):\n",
    "                tiki.fire_cannon()\n",
    "                time.sleep(0.01)\n",
    "        \n",
    "        return ret\n",
    "\n",
    "predictor = Predictor('branch1/pts/tank_v2.pt')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac24ecd68f3d4e60ba41550eba0214be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3264 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3264 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1640 x 1232 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 120.000005 fps Duration = 8333333 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 5 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 120.000005 \n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@14.348] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 enemy tank, 193.0ms\n",
      "Speed: 21.7ms preprocess, 193.0ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 124.1ms\n",
      "Speed: 6.9ms preprocess, 124.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 124.9ms\n",
      "Speed: 6.2ms preprocess, 124.9ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 122.8ms\n",
      "Speed: 6.3ms preprocess, 122.8ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 123.7ms\n",
      "Speed: 5.9ms preprocess, 123.7ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 122.5ms\n",
      "Speed: 5.3ms preprocess, 122.5ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 125.6ms\n",
      "Speed: 4.4ms preprocess, 125.6ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 122.4ms\n",
      "Speed: 5.5ms preprocess, 122.4ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 125.7ms\n",
      "Speed: 5.1ms preprocess, 125.7ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 enemy tank, 122.6ms\n",
      "Speed: 5.6ms preprocess, 122.6ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "((0, 0, 0, 1), 10)\n",
      "\n",
      "0: 480x640 1 friendly tank, 232.2ms\n",
      "Speed: 18.1ms preprocess, 232.2ms inference, 7.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly tank, 129.1ms\n",
      "Speed: 5.8ms preprocess, 129.1ms inference, 7.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly person, 1 friendly tank, 122.8ms\n",
      "Speed: 5.5ms preprocess, 122.8ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly tank, 125.0ms\n",
      "Speed: 5.0ms preprocess, 125.0ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly person, 1 friendly tank, 122.5ms\n",
      "Speed: 4.4ms preprocess, 122.5ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly tank, 123.3ms\n",
      "Speed: 5.6ms preprocess, 123.3ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly tank, 122.5ms\n",
      "Speed: 5.4ms preprocess, 122.5ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly person, 1 friendly tank, 123.1ms\n",
      "Speed: 5.7ms preprocess, 123.1ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly tank, 123.4ms\n",
      "Speed: 6.4ms preprocess, 123.4ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 friendly tank, 122.5ms\n",
      "Speed: 6.5ms preprocess, 122.5ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "((0, 0, 1, 0), 7)\n",
      "((1, 0, 1, 0), 3)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 197.0ms\n",
      "Speed: 21.6ms preprocess, 197.0ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 122.5ms\n",
      "Speed: 5.7ms preprocess, 122.5ms inference, 8.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 123.6ms\n",
      "Speed: 6.3ms preprocess, 123.6ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 122.7ms\n",
      "Speed: 5.3ms preprocess, 122.7ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 124.1ms\n",
      "Speed: 5.8ms preprocess, 124.1ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 125.2ms\n",
      "Speed: 5.2ms preprocess, 125.2ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 123.0ms\n",
      "Speed: 5.5ms preprocess, 123.0ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 122.6ms\n",
      "Speed: 7.5ms preprocess, 122.6ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 friendly persons, 2 enemy persons, 1 enemy tank, 124.6ms\n",
      "Speed: 4.3ms preprocess, 124.6ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "((2, 2, 0, 1), 10)\n",
      "\n",
      "0: 480x640 3 friendly persons, 1 enemy person, 1 friendly tank, 193.9ms\n",
      "Speed: 19.4ms preprocess, 193.9ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 friendly persons, 1 enemy person, 1 friendly tank, 124.8ms\n",
      "Speed: 5.6ms preprocess, 124.8ms inference, 7.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 friendly persons, 1 enemy person, 1 friendly tank, 124.2ms\n",
      "Speed: 13.2ms preprocess, 124.2ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 friendly persons, 1 enemy person, 1 friendly tank, 123.1ms\n",
      "Speed: 4.8ms preprocess, 123.1ms inference, 7.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 friendly persons, 1 enemy person, 1 friendly tank, 122.4ms\n",
      "Speed: 6.0ms preprocess, 122.4ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 friendly persons, 1 enemy person, 1 friendly tank, 124.2ms\n",
      "Speed: 5.8ms preprocess, 124.2ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 friendly persons, 1 enemy person, 1 friendly tank, 123.7ms\n",
      "Speed: 5.6ms preprocess, 123.7ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 friendly persons, 1 enemy person, 1 friendly tank, 122.8ms\n",
      "Speed: 5.8ms preprocess, 122.8ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 friendly persons, 1 enemy person, 1 friendly tank, 124.0ms\n",
      "Speed: 7.5ms preprocess, 124.0ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 friendly persons, 1 enemy person, 1 friendly tank, 122.6ms\n",
      "Speed: 4.8ms preprocess, 122.6ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "((3, 1, 1, 0), 8)\n",
      "((4, 1, 1, 0), 2)\n",
      "released\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 136\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;66;03m# clear_output(wait=True)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;66;03m# time.sleep(0.1)  # 프레임 간 간격\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 117\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m         event_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    116\u001b[0m         cool_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcool_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m    118\u001b[0m         cool_time \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    120\u001b[0m frame[roix_s:roix_e, roiy_s:roiy_e] \u001b[38;5;241m=\u001b[39m crop_img\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    video_widget = widgets.Image(format='jpeg')\n",
    "    \n",
    "    tiki.log_clear()\n",
    "    for led_num in range(8):\n",
    "        tiki.set_led_color(led_num, 0, 0, 0)\n",
    "    tiki.set_motor_mode(tiki.MOTOR_MODE_PID)\n",
    "    \n",
    "    event_detection_count = 0\n",
    "    event_detection_threshold = 3\n",
    "    \n",
    "    event_cnt = 0\n",
    "    \n",
    "    cool_flag = 1\n",
    "    cool_time = 0\n",
    "    cx = 0\n",
    "    start_cx = None\n",
    "    start_time = time.time()  # 시작 시간 기록\n",
    "\n",
    "    callbacks = [] \n",
    "    add_callback(callbacks, tiki.stop, 8)\n",
    "    Mission_idx = [1,3,5,6]\n",
    "    ev_flag = False\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display(video_widget)\n",
    "\n",
    "    # for frame in capture_generator():\n",
    "    # with TestCapture() as cap:\n",
    "    with TestCapture() as (cap, out):\n",
    "        while True:\n",
    "            frame = read_realtime(cap)\n",
    "            if frame is None:\n",
    "                break\n",
    "                \n",
    "            t_cur = time.time()\n",
    "            for callback, end_time in callbacks:\n",
    "                if t_cur <= end_time:\n",
    "                    callback()\n",
    "                    break\n",
    "            callbacks = list(filter(lambda c_t: c_t[1] > t_cur, callbacks))\n",
    "            \"\"\"\n",
    "            if out is not None:\n",
    "                out.write(frame)\n",
    "            \"\"\"\n",
    "            # Line\n",
    "            crop_img, lines = detect_lines(frame)\n",
    "            \n",
    "            if len(lines) > 0:\n",
    "                c = max(lines, key=cv2.contourArea)\n",
    "                M = cv2.moments(c)\n",
    "                if M['m00'] != 0:\n",
    "                    cx = int(M['m10']/M['m00'])\n",
    "                    #cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "                    # 3초 후의 cx 값을 start_cx로 설정\n",
    "                    if start_cx is None and t_cur - start_time >= 3:\n",
    "                        start_cx = cx  \n",
    "    \n",
    "            cv2.drawContours(crop_img, lines, -1, (0,255,0), 1)\n",
    "            if len(callbacks) == 0:\n",
    "                \n",
    "                ## Predict ##\n",
    "                if ev_flag and event_cnt-1 in Mission_idx:\n",
    "                    res = predictor.predict(cap, video_widget,n=10)\n",
    "                    \n",
    "                    if event_cnt-1 == 1:\n",
    "                        tiki.log(f\"A AF-{res[0]} EF-{res[1]}\")\n",
    "                        add_callback(callbacks, turn_90, 1.5, 'left')    \n",
    "                        add_callback(callbacks, tiki.stop, 2) \n",
    "                    elif event_cnt-1 == 3:\n",
    "                        tiki.log(f\"B AF-{res[0]} EF-{res[1]}\")\n",
    "                        add_callback(callbacks, turn_90, 1.5, 'right')   \n",
    "                        add_callback(callbacks, tiki.stop, 2) \n",
    "                    elif event_cnt-1 == 5:\n",
    "                        tiki.log(f\"C AF-{res[0]} EF-{res[1]}\")\n",
    "                        add_callback(callbacks, turn_90, 1.5, 'right')       \n",
    "                        add_callback(callbacks, tiki.stop, 2) \n",
    "                    elif event_cnt-1 == 6:\n",
    "                        tiki.log(f\"D AF-{res[0]} EF-{res[1]}\")\n",
    "                        add_callback(callbacks, turn_90, 1.5, 'right')    \n",
    "                        add_callback(callbacks, tiki.stop, 2) \n",
    "                ev_flag = False\n",
    "                \n",
    "                if start_cx is not None:\n",
    "                    adjust_wheel_speed(cx, start_cx)\n",
    "                \n",
    "                # Event Detection\n",
    "                start_x, start_y, end_x, end_y = calculate_center_area(frame)\n",
    "                center = frame[start_y:end_y, start_x:end_x]\n",
    "                event_mask = detect_event_color(center, lower_event, upper_event)\n",
    "                event_detected, event_point = detect_event_in_center(event_mask, start_x, start_y)\n",
    "                \n",
    "                if event_detected:\n",
    "                    event_detection_count += 1\n",
    "                else:\n",
    "                    event_detection_count = 0\n",
    "                \n",
    "                cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)\n",
    "        \n",
    "                if event_point:\n",
    "                    cv2.circle(frame, event_point, 10, (0, 255, 0), -1)\n",
    "                    cv2.putText(frame, f\"Green: ({event_point[0]}, {event_point[1]})\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                # Event \n",
    "                if cool_time <= 0:\n",
    "                    cool_flag = 1\n",
    "                if(event_detection_count >= event_detection_threshold and cool_flag): \n",
    "                    cool_time = Event_Handler(callbacks, event_cnt)\n",
    "                    tiki.stop()\n",
    "                    ev_flag = True\n",
    "    \n",
    "                        \n",
    "                    event_cnt += 1\n",
    "                    cool_flag = 0\n",
    "                if cool_time > 0:\n",
    "                    cool_time -= 1\n",
    "          \n",
    "            frame[roix_s:roix_e, roiy_s:roiy_e] = crop_img\n",
    "    \n",
    "            cv2.putText(frame, f\"Current Event: {event_cnt}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"cx: {cx}s\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "    \n",
    "            cv2.putText(frame, f\"Cool Time: {cool_time}s\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Cool Flag: {cool_flag}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"EV Flag: {ev_flag}\", (10, 170), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "    \n",
    "            _, buffer = cv2.imencode('.jpg', frame)  \n",
    "            video_widget.value = buffer.tobytes()\n",
    "            \n",
    "            # clear_output(wait=True)\n",
    "            # time.sleep(0.1)  # 프레임 간 간격\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
