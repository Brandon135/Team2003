{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "from tiki.mini import TikiMini\n",
    "from testing import capture_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiki = TikiMini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "# 실전용\n",
    "#lower_event = np.array([67, 23, 101])\n",
    "#upper_event = np.array([80, 255, 168])\n",
    "\n",
    "# 연습용\n",
    "#lower_event = np.array([41, 57, 50])\n",
    "#upper_event = np.array([52, 153, 161])\n",
    "\n",
    " #Byung Ddu ggung\n",
    "lower_event = np.array([90, 100, 100])\n",
    "upper_event = np.array([150, 255, 255])\n",
    "\n",
    "#절연테이프\n",
    "lower_line = np.array([0, 0, 47])\n",
    "upper_line = np.array([179,147,110])\n",
    "\n",
    "#연습용, 실전용\n",
    "#lower_line = np.array([0, 0, 0])\n",
    "#pper_line = np.array([220, 70, 130])\n",
    "\n",
    "roix_s = 280\n",
    "roix_e = 350\n",
    "roiy_s = 120\n",
    "roiy_e = 560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop():\n",
    "    tiki.stop()\n",
    "\n",
    "def mission():\n",
    "    tiki.set_motor_power(\"MOTOR_LEFT\", 0)\n",
    "    tiki.set_motor_power(\"MOTOR_RIGHT\", 0)\n",
    "\n",
    "def turn_90_degrees(direction):\n",
    "    turn_duration = 1.5\n",
    "    turn_power1 = 15\n",
    "    turn_power2 = 15\n",
    "\n",
    "    if direction == 'left':\n",
    "        tiki.counter_clockwise(turn_power1)\n",
    "    elif direction == 'right':\n",
    "        tiki.clockwise(turn_power2)\n",
    "    \n",
    "    time.sleep(turn_duration)\n",
    "    tiki.stop()\n",
    "\n",
    "def turn_90(direction):\n",
    "    turn_power1 = 15\n",
    "    turn_power2 = 15\n",
    "\n",
    "    if direction == 'left':\n",
    "        tiki.counter_clockwise(turn_power1)\n",
    "    elif direction == 'right':\n",
    "        tiki.clockwise(turn_power2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper:\n",
    "    def __init__(self, save_name=None):\n",
    "        self.cap = cv2.VideoCapture(\n",
    "            \"nvarguscamerasrc ! video/x-raw(memory:NVMM), width=640, height=480, framerate=15/1, format=NV12 ! \"\n",
    "            \"nvvidconv flip-method=2 ! video/x-raw, format=BGRx ! videoconvert ! video/x-raw, format=BGR ! appsink\"\n",
    "        )\n",
    "    def __enter__(self):\n",
    "        print('entered')\n",
    "        return self.cap\n",
    "    def __exit__(self,a,b,c):\n",
    "        self.cap.release()\n",
    "        print('released')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines(image):\n",
    "    \n",
    "    crop_img = image[roix_s:roix_e, roiy_s:roiy_e].copy()\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "    color_mask = cv2.inRange(hsv_image, lower_line, upper_line)\n",
    "    masked_image = cv2.bitwise_and(crop_img, crop_img, mask=color_mask)\n",
    "    gray_mask = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(gray_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    lines, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return crop_img, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_wheel_speed(cx, start_cx, event_num):\n",
    "    black_list = [0]\n",
    "    # CURVE\n",
    "    if (cx > start_cx + 70):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 50)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 10)\n",
    "    elif (cx < start_cx - 70):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 10)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 50)\n",
    "    \n",
    "    # MICRO CONTROL\n",
    "    elif (cx > start_cx + 30):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 50)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 30)\n",
    "    elif (cx < start_cx - 30):\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 50)\n",
    "        \n",
    "    # NORMAL\n",
    "    elif (start_cx - 30 < cx < start_cx + 30): \n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 30) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_event_color(image, lower_event, upper_event):\n",
    "    \n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_event, upper_event)\n",
    "    return mask\n",
    "\n",
    "def calculate_center_area(image, center_width=200, center_height=50):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    center_x = width // 2 \n",
    "    center_y = height // 2 + 10\n",
    "    start_x = center_x - center_width // 2\n",
    "    start_y = center_y - center_height // 2\n",
    "    end_x = start_x + center_width\n",
    "    end_y = start_y + center_height\n",
    "\n",
    "    return (start_x, start_y, end_x, end_y)\n",
    "\n",
    "def detect_event_in_center(center_mask, start_x, start_y):\n",
    "    event_detected = np.sum(center_mask) > 0\n",
    "    \n",
    "    event_point = None\n",
    "    if event_detected:\n",
    "        contours, _ = cv2.findContours(center_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"]) + start_x\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"]) + start_y\n",
    "                event_point = (cx, cy)\n",
    "    \n",
    "    return event_detected, event_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_callback(callbacks,callback, end_time, argu):\n",
    "    callback = partial(callback, argu)\n",
    "    callbacks.append((callback, time.time() + end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Event_Handler(callbacks, event_num):\n",
    "    Time90 = 1.5\n",
    "    if event_num == 0:\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        return 20\n",
    "    elif event_num == 1: # mission\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        \n",
    "        # Mission\n",
    "        add_callback(callbacks,tiki.counter_clockwise, 3.5, 10)\n",
    "        add_callback(callbacks,tiki.clockwise, 7.5, 10)\n",
    "        add_callback(callbacks,tiki.counter_clockwise, 9.5, 10)\n",
    "        \n",
    "        add_callback(callbacks, turn_90, 11, 'left')\n",
    "        return 15\n",
    "    elif event_num == 2:\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        return 40\n",
    "    elif event_num == 3: # mission\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        mission()\n",
    "        add_callback(callbacks, turn_90, 3, 'right')\n",
    "        return 40\n",
    "    elif event_num == 4:\n",
    "        add_callback(callbacks, turn_90, Time90, 'right')\n",
    "        return 20\n",
    "    elif event_num == 5: # mission\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        # Mission\n",
    "        add_callback(callbacks, turn_90, 3, 'right')\n",
    "        return 80\n",
    "    elif event_num == 6: # mission\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        # Mission\n",
    "        add_callback(callbacks, turn_90, 3, 'right')\n",
    "        return 40\n",
    "    elif event_num == 7:\n",
    "        add_callback(callbacks, turn_90, Time90, 'left')\n",
    "        return 20\n",
    "    elif event_num == 8:\n",
    "        stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c133186ab0e44e0989d0e09fe8405db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='bmp')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GST_ARGUS: Creating output stream\n",
      "CONSUMER: Waiting until producer is connected...\n",
      "GST_ARGUS: Available Sensor modes :\n",
      "GST_ARGUS: 3264 x 2464 FR = 21.000000 fps Duration = 47619048 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 3264 x 1848 FR = 28.000001 fps Duration = 35714284 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1920 x 1080 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1640 x 1232 FR = 29.999999 fps Duration = 33333334 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 59.999999 fps Duration = 16666667 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: 1280 x 720 FR = 120.000005 fps Duration = 8333333 ; Analog Gain range min 1.000000, max 10.625000; Exposure Range min 13000, max 683709000;\n",
      "\n",
      "GST_ARGUS: Running with following settings:\n",
      "   Camera index = 0 \n",
      "   Camera mode  = 5 \n",
      "   Output Stream W = 1280 H = 720 \n",
      "   seconds to Run    = 0 \n",
      "   Frame Rate = 120.000005 \n",
      "GST_ARGUS: Setup Complete, Starting captures for 0 seconds\n",
      "GST_ARGUS: Starting repeat capture requests.\n",
      "CONSUMER: Producer has connected; continuing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.255] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "released\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m             frametimes\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m display(video_widget)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m capture_generator():\n\u001b[1;32m     25\u001b[0m     t_cur \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback, end_time \u001b[38;5;129;01min\u001b[39;00m callbacks:\n",
      "File \u001b[0;32m~/Workspace/testing.py:68\u001b[0m, in \u001b[0;36mcapture_generator\u001b[0;34m(video)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TestCapture(video) \u001b[38;5;28;01mas\u001b[39;00m cap:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m---> 68\u001b[0m         frame \u001b[38;5;241m=\u001b[39m \u001b[43mread_realtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspace/testing.py:43\u001b[0m, in \u001b[0;36mread_realtime\u001b[0;34m(capture, threshold)\u001b[0m\n\u001b[1;32m     41\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcapture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrab\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    video_widget = widgets.Image(format='bmp')\n",
    "    \n",
    "    tiki.set_motor_mode(tiki.MOTOR_MODE_PID)\n",
    "    event_detection_count = 0\n",
    "    event_detection_threshold = 3\n",
    "    \n",
    "    event_cnt = 0\n",
    "    \n",
    "    cool_flag = 1\n",
    "    cool_time = 0\n",
    "    cx = 0\n",
    "    start_cx = None\n",
    "    start_time = time.time()  # 시작 시간 기록\n",
    "\n",
    "    frametimes = []\n",
    "    cnt = 0\n",
    "    t_prev = time.time()\n",
    "    callbacks = []\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display(video_widget)\n",
    "\n",
    "    for frame in capture_generator():\n",
    "        t_cur = time.time()\n",
    "        for callback, end_time in callbacks:\n",
    "            if t_cur <= end_time:\n",
    "                callback()\n",
    "                break\n",
    "        callbacks = list(filter(lambda c_t: c_t[1] > t_cur, callbacks))\n",
    "\n",
    "        # Line\n",
    "        crop_img, lines = detect_lines(frame)\n",
    "        \n",
    "        if len(lines) > 0:\n",
    "            c = max(lines, key=cv2.contourArea)\n",
    "            M = cv2.moments(c)\n",
    "            if M['m00'] != 0:\n",
    "                cx = int(M['m10']/M['m00'])\n",
    "                cy = int(M['m01']/M['m00'])\n",
    "\n",
    "                # 3초 후의 cx 값을 start_cx로 설정\n",
    "                if start_cx is None and t_cur - start_time >= 3:\n",
    "                    start_cx = cx  \n",
    "\n",
    "        cv2.drawContours(crop_img, lines, -1, (0,255,0), 1)\n",
    "        if len(callbacks) == 0:\n",
    "            if start_cx is not None:\n",
    "                adjust_wheel_speed(cx, start_cx, event_cnt)\n",
    "            \n",
    "            # Event Detection\n",
    "            start_x, start_y, end_x, end_y = calculate_center_area(frame)\n",
    "            center = frame[start_y:end_y, start_x:end_x]\n",
    "            event_mask = detect_event_color(center, lower_event, upper_event)\n",
    "            event_detected, event_point = detect_event_in_center(event_mask, start_x, start_y)\n",
    "            \n",
    "            if event_detected:\n",
    "                event_detection_count += 1\n",
    "            else:\n",
    "                event_detection_count = 0\n",
    "    \n",
    "            cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)\n",
    "    \n",
    "            if event_point:\n",
    "                cv2.circle(frame, event_point, 10, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, f\"Green: ({event_point[0]}, {event_point[1]})\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "            # Event \n",
    "            if cool_time <= 0:\n",
    "                cool_flag = 1\n",
    "            if(event_detection_count >= event_detection_threshold and cool_flag): \n",
    "                cool_time = Event_Handler(callbacks, event_cnt)\n",
    "                tiki.stop()\n",
    "                event_cnt += 1\n",
    "                cool_flag = 0\n",
    "            if cool_time > 0:\n",
    "                cool_time -= 1\n",
    "        \n",
    "        frame[roix_s:roix_e, roiy_s:roiy_e] = crop_img\n",
    "\n",
    "        cv2.putText(frame, f\"Current Event: {event_cnt}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"cx: {cx}s\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Cool Time: {cool_time}s\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Cool Flag: {cool_flag}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "        _, buffer = cv2.imencode('.bmp', frame)\n",
    "        video_widget.value = buffer.tobytes()\n",
    "        \n",
    "        # clear_output(wait=True)\n",
    "        # time.sleep(0.1)  # 프레임 간 간격\n",
    "\n",
    "        \n",
    "        t_cur = time.time()\n",
    "        frametimes.append(t_cur - t_prev)\n",
    "        t_prev = t_cur\n",
    "        cnt += 1\n",
    "        if cnt % 15 == 0:\n",
    "            #print(f'avg frame: {1 / np.mean(frametimes):.2f} fps')\n",
    "            frametimes.clear()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
