{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "from tiki.mini import TikiMini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiki = TikiMini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "#lower_green = np.array([67, 23, 101])\n",
    "#upper_green = np.array([80, 255, 168])\n",
    "\n",
    "# Byung Ddu ggung\n",
    "lower_event = np.array([90, 100, 100])\n",
    "upper_event = np.array([150, 255, 255])\n",
    "\n",
    "\n",
    "lower_line = np.array([0, 0, 0])\n",
    "upper_line = np.array([180, 255, 90])\n",
    "\n",
    "rho = 1\n",
    "theta = np.pi / 180\n",
    "threshold = 80\n",
    "min_line_length = 50\n",
    "max_line_gap = 10\n",
    "angle_threshold = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper:\n",
    "    def __init__(self, save_name=None):\n",
    "        self.cap = cv2.VideoCapture(\n",
    "            \"nvarguscamerasrc ! video/x-raw(memory:NVMM), width=640, height=480, framerate=15/1, format=NV12 ! \"\n",
    "            \"nvvidconv flip-method=2 ! video/x-raw, format=BGRx ! videoconvert ! video/x-raw, format=BGR ! appsink\"\n",
    "        )\n",
    "    def __enter__(self):\n",
    "        print('entered')\n",
    "        return self.cap\n",
    "    def __exit__(self,a,b,c):\n",
    "        self.cap.release()\n",
    "        print('released')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines(image):\n",
    "    \n",
    "    crop_img = image[300:480, 200:480].copy()\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "    color_mask = cv2.inRange(hsv_image, lower_line, upper_line)\n",
    "    masked_image = cv2.bitwise_and(crop_img, crop_img, mask=color_mask)\n",
    "    gray_mask = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(gray_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    lines, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return crop_img, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_wheel_speed(cx):\n",
    "    if (cx > 160):\n",
    "        if (cx > 200): # LEFT CORNER\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 50)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 10)\n",
    "        else: # LINE\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 50)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 30)\n",
    "    elif (cx < 100):\n",
    "        if (cx < 60): # RIGHT CORNER\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 10)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 50)\n",
    "        else: # LINE\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 50)\n",
    "    else: # NORMAL\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 30)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_event_color(image, lower_event, upper_event):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_event, upper_event)\n",
    "    return mask\n",
    "\n",
    "def calculate_center_area(image, center_width=200, center_height=60):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    center_x = width // 2 \n",
    "    center_y = height // 2 + 10\n",
    "    start_x = center_x - center_width // 2\n",
    "    start_y = center_y - center_height // 2\n",
    "    end_x = start_x + center_width\n",
    "    end_y = start_y + center_height\n",
    "\n",
    "    return (start_x, start_y, end_x, end_y)\n",
    "\n",
    "def detect_event_in_center(mask, center_coords):\n",
    "    start_x, start_y, end_x, end_y = center_coords\n",
    "    center_mask = mask[start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    event_detected = np.sum(center_mask) > 0\n",
    "    \n",
    "    event_point = None\n",
    "    if event_detected:\n",
    "        contours, _ = cv2.findContours(center_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"]) + start_x\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"]) + start_y\n",
    "                event_point = (cx, cy)\n",
    "    \n",
    "    return event_detected, event_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452be35b75b24dd5a4e035bd63d32656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "released\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.03\u001b[39m)  \u001b[38;5;66;03m# 프레임 간 간격\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 70\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m display(video_widget)\n\u001b[0;32m---> 70\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 카메라에서 실시간 이미지 출력하는 함수\n",
    "def main():\n",
    "    video_widget = widgets.Image(format='jpeg')\n",
    "    tiki.set_motor_mode(tiki.MOTOR_MODE_PID)\n",
    "    event_detection_count = 0\n",
    "    event_detection_threshold = 5\n",
    "    \n",
    "    with Wrapper() as cap:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Line\n",
    "            crop_img, lines = detect_lines(frame)\n",
    "            \n",
    "            if len(lines) > 0:\n",
    "                \n",
    "                c = max(lines, key=cv2.contourArea)\n",
    "                M = cv2.moments(c)\n",
    "                if M['m00'] != 0:\n",
    "                    cx = int(M['m10']/M['m00'])\n",
    "                    cy = int(M['m01']/M['m00'])\n",
    "\n",
    "                #cv2.line(crop_img,(cx,0),(cx,640),(255,0,0),1)\n",
    "                #cv2.line(crop_img,(0,cy),(480,cy),(255,0,0),1)\n",
    "                cv2.drawContours(crop_img, lines, -1, (0,255,0), 1)\n",
    "\n",
    "            adjust_wheel_speed(cx)\n",
    "        \n",
    "            # Event Detection\n",
    "            event_mask = detect_event_color(frame, lower_event, upper_event)\n",
    "            center_coords = calculate_center_area(event_mask)\n",
    "            event_detected, event_point = detect_event_in_center(event_mask, center_coords)\n",
    "            \n",
    "            if event_detected:\n",
    "                event_detection_count += 1\n",
    "            else:\n",
    "                event_detection_count = 0 \n",
    "                \n",
    "            event_area = cv2.bitwise_and(frame, frame, mask=event_mask)\n",
    "            \n",
    "            alpha = 0.3\n",
    "            mask = event_mask.astype(bool)\n",
    "            frame[mask] = cv2.addWeighted(frame, alpha, event_area, 1 - alpha, 0)[mask]\n",
    "\n",
    "            start_x, start_y, end_x, end_y = center_coords\n",
    "            cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)\n",
    "\n",
    "            if event_point:\n",
    "                cv2.circle(frame, event_point, 10, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, f\"Green: ({event_point[0]}, {event_point[1]})\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            if(event_detection_count >= event_detection_threshold):\n",
    "                print(\"객체탐지\")\n",
    "                \n",
    "            frame[300:480, 200:480] = crop_img\n",
    "            cv2.putText(frame, f\"cx: {cx}s\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "            #left_encoder = tiki.get_encoder(tiki.MOTOR_LEFT)\n",
    "            #right_encoder = tiki.get_encoder(tiki.MOTOR_RIGHT)\n",
    "            #cv2.putText(frame, f\"L_Motor: {left_encoder}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            #cv2.putText(frame, f\"R_Motor: {right_encoders}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            \n",
    "            _, buffer = cv2.imencode('.jpg', frame)\n",
    "            video_widget.value = buffer.tobytes()\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            display(video_widget)\n",
    "            time.sleep(0.03)  # 프레임 간 간격\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
