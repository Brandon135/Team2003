{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "from tiki.mini import TikiMini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiki = TikiMini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "# 실전용\n",
    "#lower_event = np.array([67, 23, 101])\n",
    "#upper_event = np.array([80, 255, 168])\n",
    "\n",
    "# 연습용\n",
    "lower_event = np.array([40, 70, 50])\n",
    "upper_event = np.array([80, 150, 150])\n",
    "\n",
    "# Byung Ddu ggung\n",
    "#lower_event = np.array([90, 100, 100])\n",
    "#upper_event = np.array([150, 255, 255])\n",
    "\n",
    "# 절연테이프\n",
    "lower_line = np.array([0, 0, 0])\n",
    "upper_line = np.array([360, 255, 150])\n",
    "\n",
    "# 연습용, 실전용\n",
    "#lower_line = np.array([70, 0, 0])\n",
    "#upper_line = np.array([220, 70, 130])\n",
    "\n",
    "roix_s = 300\n",
    "roix_e = 400\n",
    "roiy_s = 200\n",
    "roiy_e = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop():\n",
    "    tiki.stop()\n",
    "    time.sleep(1)\n",
    "\n",
    "def mission():\n",
    "    tiki.set_motor_power(\"MOTOR_LEFT\", 0)\n",
    "    tiki.set_motor_power(\"MOTOR_RIGHT\", 0)\n",
    "    time.sleep(5)\n",
    "\n",
    "def turn_90_degrees(direction):\n",
    "    turn_duration = 0.75\n",
    "    turn_power = 30  \n",
    "\n",
    "    if direction == 'left':\n",
    "        tiki.counter_clockwise(turn_power)\n",
    "    elif direction == 'right':\n",
    "        tiki.clockwise(turn_power)\n",
    "\n",
    "    time.sleep(turn_duration)\n",
    "    stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper:\n",
    "    def __init__(self, save_name=None):\n",
    "        self.cap = cv2.VideoCapture(\n",
    "            \"nvarguscamerasrc ! video/x-raw(memory:NVMM), width=640, height=480, framerate=15/1, format=NV12 ! \"\n",
    "            \"nvvidconv flip-method=2 ! video/x-raw, format=BGRx ! videoconvert ! video/x-raw, format=BGR ! appsink\"\n",
    "        )\n",
    "    def __enter__(self):\n",
    "        print('entered')\n",
    "        return self.cap\n",
    "    def __exit__(self,a,b,c):\n",
    "        self.cap.release()\n",
    "        print('released')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines(image):\n",
    "    \n",
    "    crop_img = image[roix_s:roix_e, roiy_s:roiy_e].copy()\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "    color_mask = cv2.inRange(hsv_image, lower_line, upper_line)\n",
    "    masked_image = cv2.bitwise_and(crop_img, crop_img, mask=color_mask)\n",
    "    gray_mask = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(gray_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    lines, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return crop_img, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_wheel_speed(cx, cool_time):\n",
    "    if cool_time != 0:\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 0)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 0)\n",
    "    elif (100 < cx < 140): # NORMAL\n",
    "        tiki.set_motor_power(tiki.MOTOR_LEFT, 20)\n",
    "        tiki.set_motor_power(tiki.MOTOR_RIGHT, 20)   \n",
    "    elif (cx > 140):\n",
    "        if (cx > 220): # LEFT CORNER\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 30)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 10)\n",
    "        else: # LINE\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 20)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 15)\n",
    "    elif (cx < 100):\n",
    "        if (cx < 40): # RIGHT CORNER\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 10)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 30)\n",
    "        else: # LINE\n",
    "            tiki.set_motor_power(tiki.MOTOR_LEFT, 15)\n",
    "            tiki.set_motor_power(tiki.MOTOR_RIGHT, 20)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_event_color(image, lower_event, upper_event):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_event, upper_event)\n",
    "    return mask\n",
    "\n",
    "def calculate_center_area(image, center_width=200, center_height=50):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    center_x = width // 2 \n",
    "    center_y = height // 2 + 10\n",
    "    start_x = center_x - center_width // 2\n",
    "    start_y = center_y - center_height // 2\n",
    "    end_x = start_x + center_width\n",
    "    end_y = start_y + center_height\n",
    "\n",
    "    return (start_x, start_y, end_x, end_y)\n",
    "\n",
    "def detect_event_in_center(mask, center_coords):\n",
    "    start_x, start_y, end_x, end_y = center_coords\n",
    "    center_mask = mask[start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    event_detected = np.sum(center_mask) > 0\n",
    "    \n",
    "    event_point = None\n",
    "    if event_detected:\n",
    "        contours, _ = cv2.findContours(center_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            M = cv2.moments(largest_contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cx = int(M[\"m10\"] / M[\"m00\"]) + start_x\n",
    "                cy = int(M[\"m01\"] / M[\"m00\"]) + start_y\n",
    "                event_point = (cx, cy)\n",
    "    \n",
    "    return event_detected, event_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Event_Handler(event_num):\n",
    "    if event_num == 0:\n",
    "        turn_90_degrees('left')\n",
    "    elif event_num == 1: # mission\n",
    "        turn_90_degrees('left')\n",
    "        mission()\n",
    "        turn_90_degrees('left')\n",
    "    elif event_num == 2:\n",
    "        turn_90_degrees('left')\n",
    "    elif event_num == 3: # mission\n",
    "        turn_90_degrees('left')\n",
    "        mission()\n",
    "        turn_90_degrees('right')\n",
    "    elif event_num == 5:\n",
    "        turn_90_degrees('right')\n",
    "    elif event_num == 6: # mission\n",
    "        turn_90_degrees('left')\n",
    "        mission()\n",
    "        turn_90_degrees('right')\n",
    "    elif event_num == 7: # mission\n",
    "        turn_90_degrees('left')\n",
    "        mission()\n",
    "        turn_90_degrees('right')\n",
    "    elif event_num == 8:\n",
    "        turn_90_degrees('left')\n",
    "    elif event_num == 9:\n",
    "        stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1c718b072c435ab2de9d4c8147f8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "released\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.03\u001b[39m)  \u001b[38;5;66;03m# 프레임 간 간격\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 64\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Event Start \u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(event_detection_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m event_detection_threshold \u001b[38;5;129;01mand\u001b[39;00m cool_flag):\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     Event_Handler(event_cnt)\n\u001b[1;32m     66\u001b[0m     event_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mstop\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstop\u001b[39m():\n\u001b[1;32m      2\u001b[0m     tiki\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 카메라에서 실시간 이미지 출력하는 함수\n",
    "def main():\n",
    "    video_widget = widgets.Image(format='jpeg')\n",
    "    tiki.set_motor_mode(tiki.MOTOR_MODE_PID)\n",
    "    event_detection_count = 0\n",
    "    event_detection_threshold = 3\n",
    "    \n",
    "    event_cnt = 0\n",
    "    \n",
    "    cool_flag = 1\n",
    "    cool_time = 0\n",
    "    \n",
    "    with Wrapper() as cap:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Line\n",
    "            crop_img, lines = detect_lines(frame)\n",
    "            \n",
    "            if len(lines) > 0:\n",
    "                \n",
    "                c = max(lines, key=cv2.contourArea)\n",
    "                M = cv2.moments(c)\n",
    "                if M['m00'] != 0:\n",
    "                    cx = int(M['m10']/M['m00'])\n",
    "                    cy = int(M['m01']/M['m00'])\n",
    "\n",
    "                #cv2.line(crop_img,(cx,0),(cx,640),(255,0,0),1)\n",
    "                #cv2.line(crop_img,(0,cy),(480,cy),(255,0,0),1)\n",
    "                cv2.drawContours(crop_img, lines, -1, (0,255,0), 1)\n",
    "\n",
    "            adjust_wheel_speed(cx, cool_time)\n",
    "            current_time = time.time()\n",
    "            # Event Detection\n",
    "            event_mask = detect_event_color(frame, lower_event, upper_event)\n",
    "            center_coords = calculate_center_area(event_mask)\n",
    "            event_detected, event_point = detect_event_in_center(event_mask, center_coords)\n",
    "            \n",
    "            if event_detected:\n",
    "                event_detection_count += 1\n",
    "            else:\n",
    "                event_detection_count = 0 \n",
    "                \n",
    "            event_area = cv2.bitwise_and(frame, frame, mask=event_mask)\n",
    "            \n",
    "            alpha = 0.3\n",
    "            mask = event_mask.astype(bool)\n",
    "            frame[mask] = cv2.addWeighted(frame, alpha, event_area, 1 - alpha, 0)[mask]\n",
    "\n",
    "            start_x, start_y, end_x, end_y = center_coords\n",
    "            cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)\n",
    "\n",
    "            if event_point:\n",
    "                cv2.circle(frame, event_point, 10, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, f\"Green: ({event_point[0]}, {event_point[1]})\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            if cool_time <= 0:\n",
    "                cool_flag = 1\n",
    "                \n",
    "            # Event Start \n",
    "            if(event_detection_count >= event_detection_threshold and cool_flag):\n",
    "                stop()\n",
    "                Event_Handler(event_cnt)\n",
    "                event_cnt += 1\n",
    "                cool_flag = 0\n",
    "                cool_time = 100\n",
    "            if cool_time > 0:\n",
    "                cool_time -= 1\n",
    "                \n",
    "            \n",
    "            frame[roix_s:roix_e, roiy_s:roiy_e] = crop_img\n",
    "\n",
    "            cv2.putText(frame, f\"Current Event: {event_cnt}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"cx: {cx}s\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, f\"Cool Time: {cool_time}s\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Cool Flag: {cool_flag}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "            #left_encoder = tiki.get_encoder(tiki.MOTOR_LEFT)\n",
    "            #right_encoder = tiki.get_encoder(tiki.MOTOR_RIGHT)\n",
    "            #cv2.putText(frame, f\"L_Motor: {left_encoder}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            #cv2.putText(frame, f\"R_Motor: {right_encoders}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "            \n",
    "            _, buffer = cv2.imencode('.jpg', frame)\n",
    "            video_widget.value = buffer.tobytes()\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            display(video_widget)\n",
    "            time.sleep(0.03)  # 프레임 간 간격\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
